* Relevant literature
 * cite:goCompositionalPreferenceModels2024 The orginal paper about compositional preference models on archive
 * cite:xuOrthogonalClassifierImproving2021 # Lists several previous work about orthogonal
 * cite:simardTangentPropFormalism1991 # Specifying invariances
 * There is another paper like tangentprop
 * https://openreview.net/forum?id=tiiAzqi6Ol The openreview comments that deal with the paper
 * cite:el-shangitiGeometryNumericalReasoning2024 Project onto a subspace: But it is focussed on numerical attributes, uses last activation
 * cite:kwakLanguageDetoxificationAttributeDiscriminative2023 Makes use of projection module for the sake of language detoxification.
 * cite:lambertRewardBenchEvaluatingReward2024  The rewardbench paper and its github: https://github.com/allenai/reward-bench
 * cite:baiConstitutionalAIHarmlessness2022 The constitutional AI paper

* Other resources
 * https://github.com/dongyoung-go/CPM The github repo with the code

Resources: https://openreview.net/forum?id=tiiAzqi6Ol

Read these that cite the cpms
https://arxiv.org/abs/2410.20290
https://arxiv.org/abs/2406.07295
https://dspace.mit.edu/handle/1721.1/156747


# Reward Models
https://huggingface.co/Ray2333/GRM-Llama3.2-3B-rewardmodel-ft For example use this model with different viewpoints.
https://huggingface.co/Skywork/Skywork-Reward-Gemma-2-27B-v0.2

# Datasets
https://huggingface.co/datasets/HuggingFaceH4/cai-conversation-harmless/viewer/default/train_sft?row=2 # Conversational harmlessness dataset
https://huggingface.co/datasets/pbevan11/ultrafeedback_binarized_multilingual/viewer/default/train_sft?sort[column]=language&sort[direction]=desc # Multilingual preference dataset
https://huggingface.co/datasets/Anthropic/hh-rlhf?row=12 # The Anthopic hh-rlhf dataset


* Possible tools
 * JIVE joint and Individual Variation Explained to get to a point where you can he a linear model with orthogonal components cite:fengAngleBasedJointIndividual2018
 * https://huggingface.co/spaces/allenai/reward-bench Reward-bech for reward model bechmark
 * https://python.langchain.com/v0.1/docs/guides/productionization/safety/constitutional_chain/ # Langchain constitution chain.
 * https://python.langchain.com/api_reference/langchain/chains/langchain.chains.constitutional_ai.base.ConstitutionalChain.html#langchain.chains.constitutional_ai.base.ConstitutionalChain # New way to build a constitutional chain in langchain
 * https://pol.is/report/r3rwrinr5udrzwkvxtdkj # List of possible consitutions
         * Associated antrhopic blog post  https://www.anthropic.com/news/collective-constitutional-ai-aligning-a-language-model-with-public-input

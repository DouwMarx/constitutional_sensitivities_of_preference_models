* Relevant literature
 * cite:goCompositionalPreferenceModels2024 The orginal paper about compositional preference models on archive
 * cite:xuOrthogonalClassifierImproving2021 # Lists several previous work about orthogonal
 * cite:simardTangentPropFormalism1991 # Specifying invariances
 * There is another paper like tangentprop
 * https://openreview.net/forum?id=tiiAzqi6Ol The openreview comments that deal with the paper
 * cite:el-shangitiGeometryNumericalReasoning2024 Project onto a subspace: But it is focussed on numerical attributes, uses last activation
 * cite:kwakLanguageDetoxificationAttributeDiscriminative2023 Makes use of projection module for the sake of language detoxification.
 * cite:lambertRewardBenchEvaluatingReward2024  The rewardbench paper and its github: https://github.com/allenai/reward-bench
 * cite:baiConstitutionalAIHarmlessness2022 The constitutional AI paper
 * https://en.wikipedia.org/wiki/Variance-based_sensitivity_analysis Sobol indices
 * cite:LouyangTrainingLanguageModels2022 The instruct gpt paper that does the rlhf bussiness after supervised fine tuning.


* Other resources
** Compositional preference models
 * https://github.com/dongyoung-go/CPM The github repo with the code
 Resources: https://openreview.net/forum?id=tiiAzqi6Ol

  Read these that cite the cpms
  https://arxiv.org/abs/2410.20290
  https://arxiv.org/abs/2406.07295
  https://dspace.mit.edu/handle/1721.1/156747

** Reward models
    https://huggingface.co/Ray2333/GRM-Llama3.2-3B-rewardmodel-ft For example use this model with different viewpoints.
    https://huggingface.co/Skywork/Skywork-Reward-Gemma-2-27B-v0.2

** Datasets
*** Candidates
https://huggingface.co/datasets/HuggingFaceH4/cai-conversation-harmless/viewer/default/train_sft?row=2 # Conversational harmlessness dataset
https://huggingface.co/datasets/pbevan11/ultrafeedback_binarized_multilingual/viewer/default/train_sft?sort[column]=language&sort[direction]=desc # Multilingual preference dataset

*** Antrhopic hhrlhf

https://huggingface.co/datasets/Anthropic/hh-rlhf?row=12 # The Anthopic hh-rlhf dataset

*** Collective consitutional AI
https://github.com/saffronh/ccai
https://www.anthropic.com/news/collective-constitutional-ai-aligning-a-language-model-with-public-input
https://pol.is/report/r3rwrinr5udrzwkvxtdkj


* Possible tools
 * JIVE joint and Individual Variation Explained to get to a point where you can he a linear model with orthogonal components cite:fengAngleBasedJointIndividual2018
 * https://huggingface.co/spaces/allenai/reward-bench Reward-bech for reward model bechmark
 * https://python.langchain.com/v0.1/docs/guides/productionization/safety/constitutional_chain/ # Langchain constitution chain.
 * https://python.langchain.com/api_reference/langchain/chains/langchain.chains.constitutional_ai.base.ConstitutionalChain.html#langchain.chains.constitutional_ai.base.ConstitutionalChain # New way to build a constitutional chain in langchain
 * https://pol.is/report/r3rwrinr5udrzwkvxtdkj # List of possible consitutions
         * Associated antrhopic blog post  https://www.anthropic.com/news/collective-constitutional-ai-aligning-a-language-model-with-public-input


 Runpod
 Kaggle service 
 google
